### YamlMime:ManagedReference
items:
- uid: SiaNet.Optimizers.Adagrad
  commentId: T:SiaNet.Optimizers.Adagrad
  id: Adagrad
  parent: SiaNet.Optimizers
  children:
  - SiaNet.Optimizers.Adagrad.#ctor(System.Single,System.Single,System.Single)
  - SiaNet.Optimizers.Adagrad.Epsilon
  langs:
  - csharp
  - vb
  name: Adagrad
  nameWithType: Adagrad
  fullName: SiaNet.Optimizers.Adagrad
  type: Class
  source:
    remote:
      path: SiaNet/Optimizers/Adagrad.cs
      branch: master
      repo: https://github.com/deepakkumar1984/SiaNet
    id: Adagrad
    path: ../SiaNet/Optimizers/Adagrad.cs
    startLine: 10
  assemblies:
  - SiaNet
  namespace: SiaNet.Optimizers
  summary: "\nAdagrad is an optimizer with parameter-specific learning rates, which are adapted relative to how frequently a parameter gets updated during training. The more updates a parameter receives, the smaller the learning rate.\n"
  example: []
  syntax:
    content: 'public class Adagrad : BaseOptimizer'
    content.vb: >-
      Public Class Adagrad
          Inherits BaseOptimizer
  seealso:
  - linkId: SiaNet.Optimizers.BaseOptimizer
    commentId: T:SiaNet.Optimizers.BaseOptimizer
  inheritance:
  - System.Object
  - SiaNet.Optimizers.BaseOptimizer
  inheritedMembers:
  - SiaNet.Optimizers.BaseOptimizer.Name
  - SiaNet.Optimizers.BaseOptimizer.LearningRate
  - SiaNet.Optimizers.BaseOptimizer.Momentum
  - SiaNet.Optimizers.BaseOptimizer.DecayRate
  modifiers.csharp:
  - public
  - class
  modifiers.vb:
  - Public
  - Class
- uid: SiaNet.Optimizers.Adagrad.Epsilon
  commentId: P:SiaNet.Optimizers.Adagrad.Epsilon
  id: Epsilon
  parent: SiaNet.Optimizers.Adagrad
  langs:
  - csharp
  - vb
  name: Epsilon
  nameWithType: Adagrad.Epsilon
  fullName: SiaNet.Optimizers.Adagrad.Epsilon
  type: Property
  source:
    remote:
      path: SiaNet/Optimizers/Adagrad.cs
      branch: master
      repo: https://github.com/deepakkumar1984/SiaNet
    id: Epsilon
    path: ../SiaNet/Optimizers/Adagrad.cs
    startLine: 18
  assemblies:
  - SiaNet
  namespace: SiaNet.Optimizers
  summary: "\nFuzz factor. Lowest float value but > 0\n"
  example: []
  syntax:
    content: public float Epsilon { get; set; }
    parameters: []
    return:
      type: System.Single
      description: "\nThe epsilon.\n"
    content.vb: Public Property Epsilon As Single
  overload: SiaNet.Optimizers.Adagrad.Epsilon*
  modifiers.csharp:
  - public
  - get
  - set
  modifiers.vb:
  - Public
- uid: SiaNet.Optimizers.Adagrad.#ctor(System.Single,System.Single,System.Single)
  commentId: M:SiaNet.Optimizers.Adagrad.#ctor(System.Single,System.Single,System.Single)
  id: '#ctor(System.Single,System.Single,System.Single)'
  parent: SiaNet.Optimizers.Adagrad
  langs:
  - csharp
  - vb
  name: Adagrad(Single, Single, Single)
  nameWithType: Adagrad.Adagrad(Single, Single, Single)
  fullName: SiaNet.Optimizers.Adagrad.Adagrad(System.Single, System.Single, System.Single)
  type: Constructor
  source:
    remote:
      path: SiaNet/Optimizers/Adagrad.cs
      branch: master
      repo: https://github.com/deepakkumar1984/SiaNet
    id: .ctor
    path: ../SiaNet/Optimizers/Adagrad.cs
    startLine: 28
  assemblies:
  - SiaNet
  namespace: SiaNet.Optimizers
  summary: "\nInitializes a new instance of the <xref href=\"SiaNet.Optimizers.Adagrad\" data-throw-if-not-resolved=\"false\"></xref> class.\n"
  example: []
  syntax:
    content: public Adagrad(float lr = 0.01F, float decayRate = 0F, float epsilon = 1E-07F)
    parameters:
    - id: lr
      type: System.Single
      description: Initial learning rate for the optimizer.
    - id: decayRate
      type: System.Single
      description: Learning rate decay over each update.
    - id: epsilon
      type: System.Single
      description: Fuzz factor. Lowest float value but > 0
    content.vb: Public Sub New(lr As Single = 0.01F, decayRate As Single = 0F, epsilon As Single = 1E-07F)
  overload: SiaNet.Optimizers.Adagrad.#ctor*
  modifiers.csharp:
  - public
  modifiers.vb:
  - Public
references:
- uid: SiaNet.Optimizers.BaseOptimizer
  commentId: T:SiaNet.Optimizers.BaseOptimizer
  parent: SiaNet.Optimizers
  name: BaseOptimizer
  nameWithType: BaseOptimizer
  fullName: SiaNet.Optimizers.BaseOptimizer
- uid: SiaNet.Optimizers
  commentId: N:SiaNet.Optimizers
  name: SiaNet.Optimizers
  nameWithType: SiaNet.Optimizers
  fullName: SiaNet.Optimizers
- uid: System.Object
  commentId: T:System.Object
  parent: System
  isExternal: true
  name: Object
  nameWithType: Object
  fullName: System.Object
- uid: SiaNet.Optimizers.BaseOptimizer.Name
  commentId: P:SiaNet.Optimizers.BaseOptimizer.Name
  parent: SiaNet.Optimizers.BaseOptimizer
  name: Name
  nameWithType: BaseOptimizer.Name
  fullName: SiaNet.Optimizers.BaseOptimizer.Name
- uid: SiaNet.Optimizers.BaseOptimizer.LearningRate
  commentId: P:SiaNet.Optimizers.BaseOptimizer.LearningRate
  parent: SiaNet.Optimizers.BaseOptimizer
  name: LearningRate
  nameWithType: BaseOptimizer.LearningRate
  fullName: SiaNet.Optimizers.BaseOptimizer.LearningRate
- uid: SiaNet.Optimizers.BaseOptimizer.Momentum
  commentId: P:SiaNet.Optimizers.BaseOptimizer.Momentum
  parent: SiaNet.Optimizers.BaseOptimizer
  name: Momentum
  nameWithType: BaseOptimizer.Momentum
  fullName: SiaNet.Optimizers.BaseOptimizer.Momentum
- uid: SiaNet.Optimizers.BaseOptimizer.DecayRate
  commentId: P:SiaNet.Optimizers.BaseOptimizer.DecayRate
  parent: SiaNet.Optimizers.BaseOptimizer
  name: DecayRate
  nameWithType: BaseOptimizer.DecayRate
  fullName: SiaNet.Optimizers.BaseOptimizer.DecayRate
- uid: System
  commentId: N:System
  isExternal: true
  name: System
  nameWithType: System
  fullName: System
- uid: SiaNet.Optimizers.Adagrad.Epsilon*
  commentId: Overload:SiaNet.Optimizers.Adagrad.Epsilon
  name: Epsilon
  nameWithType: Adagrad.Epsilon
  fullName: SiaNet.Optimizers.Adagrad.Epsilon
- uid: System.Single
  commentId: T:System.Single
  parent: System
  isExternal: true
  name: Single
  nameWithType: Single
  fullName: System.Single
- uid: SiaNet.Optimizers.Adagrad
  commentId: T:SiaNet.Optimizers.Adagrad
  name: Adagrad
  nameWithType: Adagrad
  fullName: SiaNet.Optimizers.Adagrad
- uid: SiaNet.Optimizers.Adagrad.#ctor*
  commentId: Overload:SiaNet.Optimizers.Adagrad.#ctor
  name: Adagrad
  nameWithType: Adagrad.Adagrad
  fullName: SiaNet.Optimizers.Adagrad.Adagrad
